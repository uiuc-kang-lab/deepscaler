from typing import Any, Callable

import concurrent.futures

from functools import partial, reduce
from inspect_ai.dataset import Dataset, hf_dataset, Sample

from .task_data import TASK_TO_CONTEXT, CONTEXT, TASK_TO_QUESTION_KEY

def get_dataset(subsets: list[str] | str | None, allowed_subsets: set[str], record_to_sample: Callable[[dict[str, Any], str], Sample]) -> Dataset:
    subsets = resolve_subsets(subsets or allowed_subsets)
    for s in subsets:
        if s not in allowed_subsets:
            raise ValueError(f"Subset {s} not in {allowed_subsets}")
    return load_and_concatenate_datasets(["TheFinAI/" + s for s in subsets], path="TheFinAI", record_to_sample=record_to_sample)

def load_dataset(subset: str, path: str, record_to_sample: Callable[[dict[str, Any], str], Sample], split: str = "test") -> Dataset:
    return hf_dataset(path, name="default", split=split, trust=True, sample_fields=partial(record_to_sample, subset=subset))

def load_and_concatenate_datasets(
    subsets: list[str], path: str, record_to_sample: Callable[[dict[str, Any], str], Sample], split: str = "test",
) -> Dataset:
    """
    Load Huggingface datasets for each subject in the list and concatenate them into a single dataset.
    Args:
        subsets (list): A list of subsets to load datasets for.
        path (str, optional): The base path of the datasets.
        split (str, optional): The dataset split to load (e.g., "dev", "validation"). Defaults to "test".
    Returns:
        Dataset: A concatenated Huggingface dataset containing all subsets.
    """

    # loading datasets is very slow if not parallelized
    with concurrent.futures.ProcessPoolExecutor() as executor:
        datasets = list(executor.map(partial(load_dataset, path=path, split=split, record_to_sample=record_to_sample), subsets))
    return reduce(lambda a, b: list(a) + list(b), datasets)

def resolve_subsets(subsets: list[str] | str) -> list[str]:
    """
    Resolve the subsets into a list
    Args:
        subsets (list[str] | str): A list of subsets to load datasets for.
    Returns:
        The subsets as a list[str]
    """
    if isinstance(subsets, str):
        return subsets.split(",")
    else:
        return subsets
    
def record_to_sample_multiple_choice(record: dict[str, Any], subset: str) -> Sample:
    question_key = TASK_TO_QUESTION_KEY[subset]
    context = CONTEXT[TASK_TO_CONTEXT[subset]]
    correct_answer_idx = record["choices"].index(record["answer"])
    correct_answer_letter = chr(ord("A") + correct_answer_idx)
    return Sample(
        input=f"{context}\n\n{record[question_key]}",
        target=correct_answer_letter,
        choices=record["choices"],
        id=f"{subset}-{record['id']}",
    )

def record_to_sample_qa(record: dict[str, Any], subset: str) -> Sample:
    question_key = TASK_TO_QUESTION_KEY[subset]
    return Sample(
        input=record[question_key],
        target=record["answer"],
        id=f"{subset}-{record['id']}",
    )